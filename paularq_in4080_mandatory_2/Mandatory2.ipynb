{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139cd153",
   "metadata": {},
   "source": [
    "# MANDATORY 2\n",
    "\n",
    "### ARQUIER Paul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "813ed05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pprint\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "\n",
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "size = int(len(tagged_sents) * 0.1)\n",
    "train_sents, test_sents = tagged_sents[size:], tagged_sents[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6437e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    " def pos_features(sentence, i, history): \n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                 \"suffix(2)\": sentence[i][-2:],\n",
    "                 \"suffix(3)\": sentence[i][-3:]}\n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47e5021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsecutivePosTagger(nltk.TaggerI): \n",
    "\n",
    "    def __init__(self, train_sents, features=pos_features):\n",
    "        self.features = features\n",
    "        train_set = []\n",
    "        for tagged_sent in train_sents:\n",
    "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "            history = []\n",
    "            for i, (word, tag) in enumerate(tagged_sent):\n",
    "                featureset = features(untagged_sent, i, history)\n",
    "                train_set.append( (featureset, tag) )\n",
    "                history.append(tag)\n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    def tag(self, sentence):\n",
    "        history = []\n",
    "        for i, word in enumerate(sentence):\n",
    "            featureset = self.features(sentence, i, history)\n",
    "            tag = self.classifier.classify(featureset)\n",
    "            history.append(tag)\n",
    "        return zip(sentence, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c0557cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7915\n"
     ]
    }
   ],
   "source": [
    "tagger = ConsecutivePosTagger(train_sents)\n",
    "print(round(tagger.evaluate(test_sents), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbb12c8",
   "metadata": {},
   "source": [
    "## EXERCICE 1 : Tag set and baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf74282",
   "metadata": {},
   "source": [
    "Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b8b37fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8689\n"
     ]
    }
   ],
   "source": [
    "tagged_sents2 = brown.tagged_sents(categories='news', tagset=\"universal\")\n",
    "\n",
    "size1 = int(len(tagged_sents) * 0.1)\n",
    "size2 = int(len(tagged_sents) * 0.2)\n",
    "\n",
    "news_train, news_dev_test, news_test = tagged_sents2[size2:], tagged_sents2[size1:size2], tagged_sents2[:size1]\n",
    "\n",
    "tagger1 = ConsecutivePosTagger(news_train)\n",
    "\n",
    "print(round(tagger1.evaluate(news_dev_test), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7b2ded",
   "metadata": {},
   "source": [
    "The result is 0.8689 for the accuracy. It's higher than the result for the full brown tagset used in introduction. We can explain this result because of the size of the tagger here is smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8300d1b",
   "metadata": {},
   "source": [
    "Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04c56b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ConditionalFreqDist\n",
    "\n",
    "\n",
    "class BaselinePosTagger(nltk.TaggerI): \n",
    "    def __init__(self, train_sents):\n",
    "        self.train_sents = train_sents\n",
    "        self.cfd = ConditionalFreqDist([(word.lower(),tag) for sentence in train_sents for (word,tag) in sentence])\n",
    "        self.max_ = 0\n",
    "        self.most_common_tag = ''\n",
    "        self.most_common_pos()\n",
    "        \n",
    "    def most_common_pos(self):\n",
    "        tags = {}\n",
    "        max_  = 0\n",
    "        max_word = {}\n",
    "        for sentence in self.train_sents:\n",
    "            for word, tag in sentence:\n",
    "                tags[word] = tag\n",
    "        for key in self.cfd:\n",
    "            if self.cfd[key].N() > max_:\n",
    "                max_ = self.cfd[key].N()\n",
    "                max_word[max_] = key\n",
    "        self.max = max_\n",
    "        self.most_common_tag = tags[max_word[max_]]\n",
    "        \n",
    "        \n",
    "    def tag(self, sentence):\n",
    "        history = []\n",
    "        for i, word in enumerate(sentence):\n",
    "            if self.cfd[word].N() > 0:\n",
    "                history.append(self.cfd[word].max())\n",
    "            else:\n",
    "                history.append(self.most_common_tag)\n",
    "        return zip(sentence, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df50e13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7582\n"
     ]
    }
   ],
   "source": [
    "tagger2 = BaselinePosTagger(news_train)\n",
    "print(round(tagger2.evaluate(news_dev_test), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ac784",
   "metadata": {},
   "source": [
    "We can see that the accuracy is not the same with the BaselinePosTagger and the ConsecutivePosTagger. The result is lower but still not bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c913b2",
   "metadata": {},
   "source": [
    "# EXERCICE 2 : Scikit-learn and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6c326ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "class ScikitConsecutivePosTagger(nltk.TaggerI):\n",
    "    def __init__(self, train_sents, \n",
    "                 features=pos_features, clf = BernoulliNB()):\n",
    "        self.features = features\n",
    "        self.classifier = clf\n",
    "        self.dict = DictVectorizer()\n",
    "        \n",
    "        train_features = []\n",
    "        train_labels = []\n",
    "        for tagged_sent in train_sents:\n",
    "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "            \n",
    "            history = []\n",
    "            for i, (word, tag) in enumerate(tagged_sent):\n",
    "                featureset = features(untagged_sent, i, history)\n",
    "                train_features.append(featureset)\n",
    "                train_labels.append(tag)\n",
    "                history.append(tag)\n",
    "                \n",
    "        X_train = self.dict.fit_transform(train_features)\n",
    "        y_train = np.array(train_labels)   \n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    def tag(self, sentence):\n",
    "        test_features = []\n",
    "        history = []\n",
    "        for i, word in enumerate(sentence):\n",
    "            featureset = self.features(sentence, i, history)\n",
    "            test_features.append(featureset)\n",
    "\n",
    "        X_test = self.dict.transform(test_features)\n",
    "        tags = self.classifier.predict(X_test)\n",
    "        \n",
    "        return zip(sentence, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9c5614",
   "metadata": {},
   "source": [
    "Part a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7db2f5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.857\n"
     ]
    }
   ],
   "source": [
    "tagger3 = ScikitConsecutivePosTagger(news_train)\n",
    "print(round(tagger3.evaluate(news_dev_test), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f8b2d5",
   "metadata": {},
   "source": [
    "The result is not the same as in the Exercice 1 a . The result is very closed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2707a53f",
   "metadata": {},
   "source": [
    "Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2aecd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5000</th>\n",
       "      <td>0.8749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.8695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>0.8683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.8651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.8631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy\n",
       "1.0000    0.8570\n",
       "0.5000    0.8749\n",
       "0.1000    0.8695\n",
       "0.0100    0.8683\n",
       "0.0010    0.8651\n",
       "0.0001    0.8631"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "alphas = [1, 0.5, 0.1, 0.01, 0.001, 0.0001]\n",
    "taggerAccuracies = []\n",
    "for alpha in alphas:\n",
    "    tagger4 = ScikitConsecutivePosTagger(news_train,features=pos_features, clf = BernoulliNB(alpha=alpha))\n",
    "    taggerAccuracies.append(round(tagger4.evaluate(news_dev_test), 4))\n",
    "df = pd.DataFrame(taggerAccuracies, index=alphas,columns = ['accuracy'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6490c76",
   "metadata": {},
   "source": [
    "We have differents results when we change the alpha. We get the best result using alpha = 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac49d3f9",
   "metadata": {},
   "source": [
    "Part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "356d0b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.8874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5000</th>\n",
       "      <td>0.9166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.9244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>0.9303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.9330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.9340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy\n",
       "1.0000    0.8874\n",
       "0.5000    0.9166\n",
       "0.1000    0.9244\n",
       "0.0100    0.9303\n",
       "0.0010    0.9330\n",
       "0.0001    0.9340"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " def pos_features2(sentence, i, history): \n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                 \"suffix(2)\": sentence[i][-2:],\n",
    "                 \"suffix(3)\": sentence[i][-3:]}\n",
    "    \n",
    "    features[\"actual_word\"] = sentence[i]\n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "    return features\n",
    "\n",
    "\n",
    "taggerAccuracies = []\n",
    "for alpha in alphas:\n",
    "    tagger6 = ScikitConsecutivePosTagger(news_train,features=pos_features2, clf = BernoulliNB(alpha=alpha))\n",
    "    taggerAccuracies.append(round(tagger6.evaluate(news_dev_test), 4))\n",
    "df = pd.DataFrame(taggerAccuracies, index=alphas,columns = ['accuracy'])\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4475e8",
   "metadata": {},
   "source": [
    "The accuracy is the best with alpha = 0.0001 here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023a2661",
   "metadata": {},
   "source": [
    "# EXERCICE 3 : Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee5ec89",
   "metadata": {},
   "source": [
    "Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "138c9d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4944bf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9515\n"
     ]
    }
   ],
   "source": [
    "tagger7 = ScikitConsecutivePosTagger(news_train, features=pos_features2, clf=LogisticRegression())\n",
    "print(round(tagger7.evaluate(news_dev_test), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58c4985",
   "metadata": {},
   "source": [
    "The result is better than using the Naïve Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9effd4ec",
   "metadata": {},
   "source": [
    "Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bb96ec78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.9265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.9515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.00</th>\n",
       "      <td>0.9537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.00</th>\n",
       "      <td>0.9531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.00</th>\n",
       "      <td>0.9540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy\n",
       "0.01       0.8499\n",
       "0.10       0.9265\n",
       "1.00       0.9515\n",
       "10.00      0.9537\n",
       "100.00     0.9531\n",
       "1000.00    0.9540"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_values = [0.01, 0.1, 1.0, 10.0, 100.0,1000.0]\n",
    "accuracies = []\n",
    "\n",
    "for c in C_values:\n",
    "    clf=LogisticRegression(C=c)\n",
    "    tagger8=ScikitConsecutivePosTagger(news_train, features=pos_features2, clf=clf)\n",
    "    accuracies.append(round(tagger8.evaluate(news_dev_test), 4))\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(accuracies, index=C_values,columns = ['accuracy'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51614b2f",
   "metadata": {},
   "source": [
    "Here we used differents values of C. In this case, the model will often fit the data almost perfectly. The best C value is 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c9c5e2",
   "metadata": {},
   "source": [
    "# EXERCICE 4 : Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da64db58",
   "metadata": {},
   "source": [
    "Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a89fdbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features3(sentence, i, history): \n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                 \"suffix(2)\": sentence[i][-2:],\n",
    "                 \"suffix(3)\": sentence[i][-3:]}\n",
    "    \n",
    "    features[\"actual_word\"] = sentence[i]\n",
    "    \n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "        if i < len(sentence) - 1:\n",
    "            features[\"next-word\"] = sentence[i+1]\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "07ca5b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9637\n"
     ]
    }
   ],
   "source": [
    "tagger9 = ScikitConsecutivePosTagger(news_train, features=pos_features3, clf=LogisticRegression(C=1000))\n",
    "print(round(tagger9.evaluate(news_dev_test), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111a0f87",
   "metadata": {},
   "source": [
    "Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a7ee0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features4(sentence, i, history): \n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                 \"suffix(2)\": sentence[i][-2:],\n",
    "                 \"suffix(3)\": sentence[i][-3:]}\n",
    "    \n",
    "    features[\"actual_word\"] = sentence[i]\n",
    "    \n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "        \n",
    "        if sentence[i-1].isupper() == True:\n",
    "            features['prev-word-capitalized'] = \"UPPER\"\n",
    "        if sentence[i-1].islower()== True:\n",
    "            features['prev-word-is-lower'] = \"LOWER\"\n",
    "        if sentence[i-1].isalpha()==True:\n",
    "            features['prev-word-is-isalpha'] = \"ALPHA\"\n",
    "        if sentence[i-1].isdigit()==True:\n",
    "            features['prev-word-is-digit'] = \"DIGIT\"\n",
    "        if i < len(sentence) - 1:\n",
    "            features[\"next-word\"] = sentence[i+1]\n",
    "            if sentence[i+1].isupper()==True:\n",
    "                features['next-word-capitalized'] = \"UPPER\"\n",
    "            if sentence[i+1].islower()==True:\n",
    "                features['next-word-is-lower'] = \"LOWER\"\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b014dafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9636\n"
     ]
    }
   ],
   "source": [
    "tagger_ = ScikitConsecutivePosTagger(news_train,features=pos_features4, clf = LogisticRegression(C=1000))\n",
    "print(round(tagger_.evaluate(news_dev_test), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501f49b0",
   "metadata": {},
   "source": [
    "Here we try to have the best feature. We add the upper, lower, alpha and digit features. We obtain a accuracy of 0.9636. It's closed to 0.001 to the accuracy we find in part a. So this feature doesn't help to earn a lot of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce4519c",
   "metadata": {},
   "source": [
    "# EXERCICE 5 : Training on a larger corpus "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313e9ece",
   "metadata": {},
   "source": [
    "Part a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8c03c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "categories = [categories for categories in brown.categories() if categories != 'adventure' and categories != 'hobbies'\n",
    "              and categories!= 'news']\n",
    "rest = list(brown.tagged_sents(categories=categories, tagset='universal'))\n",
    "random.seed(2888)\n",
    "random.shuffle(rest)\n",
    "\n",
    "\n",
    "size1 = int(len(rest) * 0.1)\n",
    "size2 = int(len(rest) * 0.2)\n",
    "\n",
    "rest_train, rest_test, rest_dev_test = rest[size2:], rest[:size1], rest[size1:size2]\n",
    "\n",
    "train = rest_train + news_train\n",
    "dev_test = rest_dev_test + news_dev_test\n",
    "test = rest_test + news_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b52bc9a",
   "metadata": {},
   "source": [
    "Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4414c3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8512\n"
     ]
    }
   ],
   "source": [
    "baseline_tagger = BaselinePosTagger(train)\n",
    "print(round(baseline_tagger.evaluate(rest_test), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf1f8e8",
   "metadata": {},
   "source": [
    "Part c 15-30 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "42a9d703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9667\n"
     ]
    }
   ],
   "source": [
    "tagger_2 = ScikitConsecutivePosTagger(train,\n",
    "                                    features=pos_features4, \n",
    "                                    clf = LogisticRegression(C=1000))\n",
    "print(round(tagger_2.evaluate(dev_test), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22001c4",
   "metadata": {},
   "source": [
    "The accurary here is 0.9667. It's quite better than before. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d50875",
   "metadata": {},
   "source": [
    "# EXERCICE 6 : Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4554be56",
   "metadata": {},
   "source": [
    "Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1dd93fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import PerceptronTagger\n",
    "tagger9 = ScikitConsecutivePosTagger(train,\n",
    "                                    features=pos_features4, \n",
    "                                    clf = LogisticRegression(C=1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4ee7bcef",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ScikitConsecutivePosTagger' object has no attribute 'confusion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14148/1773989463.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgold_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdev_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagger9\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgold_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'ScikitConsecutivePosTagger' object has no attribute 'confusion'"
     ]
    }
   ],
   "source": [
    "gold_data = dev_test\n",
    "print(tagger9.confusion(gold_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89639827",
   "metadata": {},
   "source": [
    "Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cfe20de5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ScikitConsecutivePosTagger' object has no attribute 'evaluate_per_tag'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14148/964373991.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagger9\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_per_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgold_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'ScikitConsecutivePosTagger' object has no attribute 'evaluate_per_tag'"
     ]
    }
   ],
   "source": [
    "print(tagger9.evaluate_per_tag(gold_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8022a49d",
   "metadata": {},
   "source": [
    "Part c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72bc362",
   "metadata": {},
   "source": [
    "In this exercice, i had some problems with confusion & evalute_per_tag functions. Maybe it's due to my version. I try to find a solution on internet but i didn't find some helps. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d350b93",
   "metadata": {},
   "source": [
    "# EXERCICE 8 : Final Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea127819",
   "metadata": {},
   "source": [
    "Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3272efe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9665\n"
     ]
    }
   ],
   "source": [
    "tagger_5 = ScikitConsecutivePosTagger(train,\n",
    "                                    features=pos_features4, \n",
    "                                    clf = LogisticRegression(C=1000))\n",
    "print(round(tagger_5.evaluate(test), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce1c145",
   "metadata": {},
   "source": [
    "The result is compared to the dev_test accuracy, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5a6d38",
   "metadata": {},
   "source": [
    "Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ffc6a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adventure = brown.tagged_sents(categories=\"adventure\", tagset='universal')\n",
    "hobbies = brown.tagged_sents(categories=\"hobbies\", tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "755dfb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9614\n"
     ]
    }
   ],
   "source": [
    "tagger10 = ScikitConsecutivePosTagger(train,\n",
    "                                    features=pos_features4, \n",
    "                                    clf = LogisticRegression(C=1000))\n",
    "print(round(tagger10.evaluate(adventure), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f97545b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9505\n"
     ]
    }
   ],
   "source": [
    "print(round(tagger10.evaluate(hobbies), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2cd6d8",
   "metadata": {},
   "source": [
    "Those 2 results are lower than the one using the test data. It can be explain because we work on the tagger before with the first data and here we used two news genres. Comparing to adventure and hobbies accuracy, the adventure is higher than the second one. We can explain the difference between the two by the fact that there is more similarity between the adventure genre and all the others, the words are more similar. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73924825",
   "metadata": {},
   "source": [
    "# EXERCICE 9 : Comparing to others taggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3de1f0",
   "metadata": {},
   "source": [
    "Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d52626ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8995\n"
     ]
    }
   ],
   "source": [
    "news_hmm_tagger = nltk.HiddenMarkovModelTagger.train(news_train)\n",
    "print(round(news_hmm_tagger.evaluate(news_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbc9e999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9521\n"
     ]
    }
   ],
   "source": [
    "news_hmm_tagger = nltk.HiddenMarkovModelTagger.train(train)\n",
    "print(round(news_hmm_tagger.evaluate(test), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5444015d",
   "metadata": {},
   "source": [
    "HMM taggers are less efficient in terms of results but the speed of execution is much higher and allows to perform more tests quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9874ce8c",
   "metadata": {},
   "source": [
    "Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4ed0a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_tagger = nltk.PerceptronTagger(load=False)\n",
    "per_tagger.train(news_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "325ce3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9652\n"
     ]
    }
   ],
   "source": [
    "print(round(per_tagger.evaluate(news_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4f1c94e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9787\n"
     ]
    }
   ],
   "source": [
    "per_tagger = nltk.PerceptronTagger(load=False)\n",
    "per_tagger.train(train)\n",
    "print(round(per_tagger.evaluate(test), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628cedd3",
   "metadata": {},
   "source": [
    "The Perceptron tagger is a little bit slower than the HMM taggers but faster than the tagger used in the others exercices. The results are also higher when you compare them with the HMM taggers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb14e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
